{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''This code uses an ANN to predict outcomes of AFL matches in 2018 based on player data from 2012-2017.'''\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#afl = pd.read_csv('C:/path/to/your/csv/file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "afl = pd.read_csv('C:/Users/the_n/OneDrive/Documents/Coding/afl-predictor/stats.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 63712 entries, 0 to 63711\n",
      "Data columns (total 37 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   Team                    63712 non-null  object \n",
      " 1   Player                  63712 non-null  object \n",
      " 2   D.O.B                   63712 non-null  object \n",
      " 3   Height                  63712 non-null  int64  \n",
      " 4   Weight                  63712 non-null  int64  \n",
      " 5   Position                63712 non-null  object \n",
      " 6   Season                  63712 non-null  int64  \n",
      " 7   Round                   63712 non-null  object \n",
      " 8   Date                    63624 non-null  object \n",
      " 9   Score                   63624 non-null  float64\n",
      " 10  Margin                  63624 non-null  float64\n",
      " 11  WinLoss                 63624 non-null  object \n",
      " 12  Opposition              63624 non-null  object \n",
      " 13  Venue                   63624 non-null  object \n",
      " 14  Disposals               63712 non-null  int64  \n",
      " 15  Kicks                   63712 non-null  int64  \n",
      " 16  Marks                   63712 non-null  int64  \n",
      " 17  Handballs               63712 non-null  int64  \n",
      " 18  Goals                   63712 non-null  int64  \n",
      " 19  Behinds                 63712 non-null  int64  \n",
      " 20  Hitouts                 63712 non-null  int64  \n",
      " 21  Tackles                 63712 non-null  int64  \n",
      " 22  Rebound50s              63712 non-null  int64  \n",
      " 23  Inside50s               63712 non-null  int64  \n",
      " 24  Clearances              63712 non-null  int64  \n",
      " 25  Clangers                63712 non-null  int64  \n",
      " 26  FreesFor                63712 non-null  int64  \n",
      " 27  FreesAgainst            63712 non-null  int64  \n",
      " 28  BrownlowVotes           63712 non-null  int64  \n",
      " 29  ContendedPossessions    63712 non-null  int64  \n",
      " 30  UncontendedPossessions  63712 non-null  int64  \n",
      " 31  ContestedMarks          63712 non-null  int64  \n",
      " 32  MarksInside50           63712 non-null  int64  \n",
      " 33  OnePercenters           63712 non-null  int64  \n",
      " 34  Bounces                 63712 non-null  int64  \n",
      " 35  GoalAssists             63712 non-null  int64  \n",
      " 36  PercentPlayed           63712 non-null  int64  \n",
      "dtypes: float64(2), int64(26), object(9)\n",
      "memory usage: 18.0+ MB\n"
     ]
    }
   ],
   "source": [
    "afl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "afl = afl.dropna(axis=0)\n",
    "afl = afl[afl['WinLoss'] != 'D']\n",
    "afl['D.O.B'] = pd.to_datetime(afl['D.O.B'])\n",
    "afl['Date'] = pd.to_datetime(afl['Date'])\n",
    "age_in_days = (afl['Date']-afl['D.O.B'])\n",
    "age_in_years = age_in_days.dt.days/365.2425\n",
    "afl['Age'] = age_in_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "grouped_data = afl.groupby(['Team','Season','Round','WinLoss','Opposition','Venue'])['Player'].apply(list).reset_index()\n",
    "players = grouped_data['Player'].to_numpy()\n",
    "\n",
    "for item in players:\n",
    "    random.shuffle(item)\n",
    "    \n",
    "grouped_data['Player'] = players\n",
    "grouped_data = grouped_data.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Adelaide', 2012, 'PF', 'L', 'Hawthorn', 'M.C.G.',\n",
       "       list(['Thompson, Scott', 'Smith, Brodie', 'Porplyzia, Jason', 'Sloane, Rory', 'Reilly, Brent', 'Rutten, Ben', 'Douglas, Richard', 'van Berlo, Nathan', 'Tippett, Kurt', 'Callinan, Ian', 'Henderson, Ricky', 'Thompson, Luke', 'Johncock, Graham', 'Doughty, Michael', 'Jacobs, Sam', 'Otten, Andy', 'Wright, Matthew', 'Walker, Taylor', 'Mackay, David', 'Petrenko, Jared', 'Dangerfield, Patrick', 'Vince, Bernie'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "ct1 = ColumnTransformer([('encoder',OneHotEncoder(),[3,4,5])], remainder='passthrough',sparse_threshold=0)\n",
    "grouped_data = ct1.fit_transform(grouped_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 'Adelaide', 2012, 'PF',\n",
       "       list(['Thompson, Scott', 'Smith, Brodie', 'Porplyzia, Jason', 'Sloane, Rory', 'Reilly, Brent', 'Rutten, Ben', 'Douglas, Richard', 'van Berlo, Nathan', 'Tippett, Kurt', 'Callinan, Ian', 'Henderson, Ricky', 'Thompson, Luke', 'Johncock, Graham', 'Doughty, Michael', 'Jacobs, Sam', 'Otten, Andy', 'Wright, Matthew', 'Walker, Taylor', 'Mackay, David', 'Petrenko, Jared', 'Dangerfield, Patrick', 'Vince, Bernie'])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = [x for x in grouped_data if x[43]<2018]\n",
    "test = [x for x in grouped_data if x[43]==2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([x[0] for x in training])\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = np.array([x[0] for x in test])\n",
    "y_test = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# player_stats is each players' average stats between 2012 and 2017.\n",
    "player_stats = afl[afl['Season'] < 2018].groupby('Player',sort=False).mean()\n",
    "player_stats = player_stats.reset_index()\n",
    "player_stats = player_stats.drop(['Season','Score','Margin'],axis=1)\n",
    "player_stats = player_stats.sample(frac=1).reset_index(drop=True)\n",
    "player_stats = player_stats.to_numpy()\n",
    "\n",
    "# Player average stats for 2018\n",
    "player_stats_2018 = afl[afl['Season'] == 2018].groupby('Player',sort=False).mean()\n",
    "player_stats_2018 = player_stats_2018.reset_index()\n",
    "player_stats_2018 = player_stats_2018.drop(['Season','Score','Margin'],axis=1)\n",
    "player_stats_2018 = player_stats_2018.sample(frac=1).reset_index(drop=True)\n",
    "player_stats_2018 = player_stats_2018.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Goodes, Brett', 183.0, 89.0, 17.045454545454547,\n",
       "       10.772727272727273, 4.045454545454546, 6.2727272727272725,\n",
       "       0.18181818181818182, 0.09090909090909091, 0.13636363636363635,\n",
       "       2.6363636363636362, 2.8181818181818183, 2.272727272727273,\n",
       "       1.3636363636363635, 2.772727272727273, 0.9545454545454546, 1.0,\n",
       "       0.09090909090909091, 6.2727272727272725, 9.909090909090908,\n",
       "       0.22727272727272727, 0.0, 1.8636363636363635, 0.5,\n",
       "       0.18181818181818182, 78.5, 29.979335024613157], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_stats[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(player_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include opposition and venue in features\n",
    "opp_teams_train = np.array([x[2:42] for x in training])\n",
    "opp_teams_test = np.array([x[2:42] for x in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,\n",
       "       0.0], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opp_teams_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [0]*len(training)\n",
    "for i in range(0,len(training)):\n",
    "    player_list = []\n",
    "    j = 0\n",
    "    for j in range(0,len(player_stats)):\n",
    "        if player_stats[j][0] in training[i][-1]:\n",
    "            player_list.append(player_stats[j][1:])\n",
    "    X_train[i] = player_list\n",
    "    \n",
    "X_train = [np.concatenate(x) for x in X_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "572\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([202.0, 106.0, 11.726315789473684, 7.063157894736842,\n",
       "       4.073684210526316, 4.663157894736842, 1.8526315789473684,\n",
       "       1.0842105263157895, 12.294736842105262, 2.2421052631578946,\n",
       "       0.23157894736842105, 1.7894736842105263, 1.3368421052631578,\n",
       "       2.1473684210526316, 1.2526315789473683, 1.263157894736842,\n",
       "       0.08421052631578947, 7.3052631578947365, 4.621052631578947,\n",
       "       1.8210526315789475, 2.0526315789473686, 2.0526315789473686,\n",
       "       0.010526315789473684, 0.43157894736842106, 79.46315789473684,\n",
       "       27.451293174722057, 181.0, 79.0, 20.346774193548388,\n",
       "       12.725806451612904, 3.4919354838709675, 7.620967741935484,\n",
       "       0.6693548387096774, 0.5645161290322581, 0.06451612903225806,\n",
       "       3.870967741935484, 1.314516129032258, 4.306451612903226,\n",
       "       3.661290322580645, 2.4274193548387095, 1.0, 0.9435483870967742,\n",
       "       0.03225806451612903, 8.435483870967742, 11.85483870967742,\n",
       "       0.22580645161290322, 0.5161290322580645, 1.3951612903225807,\n",
       "       0.532258064516129, 0.7661290322580645, 81.44354838709677,\n",
       "       27.993200275468777, 177.0, 85.0, 15.523809523809524,\n",
       "       9.619047619047619, 3.9285714285714284, 5.904761904761905,\n",
       "       1.0476190476190477, 0.6428571428571429, 0.07142857142857142,\n",
       "       2.3095238095238093, 0.7380952380952381, 2.4285714285714284,\n",
       "       1.6428571428571428, 2.238095238095238, 0.30952380952380953,\n",
       "       0.8333333333333334, 0.047619047619047616, 6.809523809523809,\n",
       "       8.523809523809524, 0.7619047619047619, 1.119047619047619,\n",
       "       1.119047619047619, 0.14285714285714285, 0.5952380952380952,\n",
       "       74.9047619047619, 28.109113416819945, 200.0, 102.0,\n",
       "       14.18978102189781, 8.021897810218977, 3.7664233576642334,\n",
       "       6.1678832116788325, 0.2846715328467153, 0.24817518248175183,\n",
       "       33.91970802919708, 2.065693430656934, 1.0656934306569343,\n",
       "       1.9562043795620438, 2.335766423357664, 1.8832116788321167,\n",
       "       0.8905109489051095, 0.7956204379562044, 0.19708029197080293,\n",
       "       6.189781021897811, 7.956204379562044, 0.9124087591240876,\n",
       "       0.27007299270072993, 2.627737226277372, 0.021897810218978103,\n",
       "       0.3722627737226277, 85.94890510948905, 26.694953043146167, 177.0,\n",
       "       81.0, 15.541666666666666, 8.583333333333334, 4.166666666666667,\n",
       "       6.958333333333333, 0.08333333333333333, 0.041666666666666664, 0.0,\n",
       "       3.0833333333333335, 1.9583333333333333, 1.2083333333333333,\n",
       "       0.8333333333333334, 1.4583333333333333, 0.875, 0.625, 0.0, 5.5,\n",
       "       9.75, 0.2916666666666667, 0.0, 3.8333333333333335,\n",
       "       0.041666666666666664, 0.20833333333333334, 85.33333333333333,\n",
       "       32.895040053297926, 184.0, 83.0, 16.71641791044776,\n",
       "       10.626865671641792, 3.91044776119403, 6.08955223880597,\n",
       "       0.373134328358209, 0.40298507462686567, 0.05970149253731343,\n",
       "       4.029850746268656, 1.5820895522388059, 2.91044776119403,\n",
       "       2.08955223880597, 2.5671641791044775, 0.7164179104477612, 1.0, 0.0,\n",
       "       6.268656716417911, 10.044776119402986, 0.3582089552238806,\n",
       "       0.2835820895522388, 1.2238805970149254, 0.029850746268656716,\n",
       "       0.4925373134328358, 83.7910447761194, 27.403915554366407, 172.0,\n",
       "       74.0, 12.448275862068966, 7.551724137931035, 2.8620689655172415,\n",
       "       4.896551724137931, 1.6206896551724137, 0.7931034482758621, 0.0,\n",
       "       1.7586206896551724, 0.3103448275862069, 2.2413793103448274,\n",
       "       0.7241379310344828, 1.6206896551724137, 0.5517241379310345,\n",
       "       0.6551724137931034, 0.034482758620689655, 5.517241379310345,\n",
       "       6.482758620689655, 0.3793103448275862, 1.103448275862069,\n",
       "       0.6551724137931034, 0.2413793103448276, 0.7931034482758621,\n",
       "       80.03448275862068, 29.739051499322724, 189.0, 90.0, 19.6171875,\n",
       "       12.3828125, 4.21875, 7.234375, 0.34375, 0.3359375, 0.03125,\n",
       "       1.859375, 3.7890625, 3.34375, 0.8828125, 2.2578125, 0.4921875,\n",
       "       0.5078125, 0.1015625, 5.3828125, 13.0390625, 0.2890625, 0.125,\n",
       "       2.21875, 1.1640625, 0.3671875, 82.5078125, 22.98733889128456,\n",
       "       194.0, 88.0, 9.88888888888889, 4.888888888888889,\n",
       "       2.888888888888889, 5.0, 0.0, 0.0, 0.0, 2.3333333333333335,\n",
       "       1.7777777777777777, 0.4444444444444444, 0.3333333333333333,\n",
       "       1.1111111111111112, 0.7777777777777778, 0.4444444444444444, 0.0,\n",
       "       3.2222222222222223, 6.777777777777778, 0.3333333333333333, 0.0,\n",
       "       5.222222222222222, 0.6666666666666666, 0.0, 89.11111111111111,\n",
       "       22.842053947415454, 185.0, 86.0, 26.336363636363636,\n",
       "       13.354545454545455, 3.7636363636363637, 12.981818181818182, 0.3,\n",
       "       0.34545454545454546, 0.14545454545454545, 5.4818181818181815,\n",
       "       1.4090909090909092, 3.9, 6.163636363636364, 3.918181818181818, 1.3,\n",
       "       1.8545454545454545, 0.5909090909090909, 12.481818181818182,\n",
       "       13.872727272727273, 0.2545454545454545, 0.24545454545454545,\n",
       "       1.1181818181818182, 0.02727272727272727, 0.4727272727272727,\n",
       "       83.96363636363637, 31.2333213238776, 178.0, 81.0, 10.725, 6.375,\n",
       "       2.325, 4.35, 0.825, 0.7, 0.05, 4.175, 0.275, 1.925, 0.9, 1.625,\n",
       "       0.775, 0.7, 0.0, 5.2, 5.175, 0.25, 0.625, 1.125, 0.275, 0.675,\n",
       "       75.825, 23.02066435313525, 189.0, 92.0, 27.248175182481752,\n",
       "       14.489051094890511, 4.197080291970803, 12.75912408759124,\n",
       "       1.167883211678832, 0.8686131386861314, 0.9124087591240876,\n",
       "       4.313868613138686, 1.3868613138686132, 5.642335766423358,\n",
       "       6.510948905109489, 3.510948905109489, 1.8686131386861313,\n",
       "       1.1240875912408759, 1.1167883211678833, 15.773722627737227,\n",
       "       11.89051094890511, 1.072992700729927, 0.8321167883211679,\n",
       "       1.3503649635036497, 0.7664233576642335, 0.635036496350365,\n",
       "       84.74452554744525, 24.718184184100465, 190.0, 98.0, 11.8, 6.0,\n",
       "       4.85, 5.8, 0.05, 0.03333333333333333, 0.08333333333333333,\n",
       "       1.4666666666666666, 1.65, 0.55, 0.2, 1.0833333333333333,\n",
       "       0.48333333333333334, 0.5833333333333334, 0.0, 3.7666666666666666,\n",
       "       8.083333333333334, 0.5333333333333333, 0.016666666666666666, 3.7,\n",
       "       0.15, 0.05, 87.83333333333333, 29.871980031531564, 193.0, 102.0,\n",
       "       14.392523364485982, 10.177570093457945, 6.570093457943925,\n",
       "       4.214953271028038, 2.485981308411215, 1.6822429906542056,\n",
       "       0.028037383177570093, 1.560747663551402, 0.09345794392523364,\n",
       "       3.5046728971962615, 0.09345794392523364, 3.0, 0.9065420560747663,\n",
       "       1.3177570093457944, 0.32710280373831774, 6.420560747663552,\n",
       "       8.242990654205608, 1.5700934579439252, 2.7196261682242993,\n",
       "       1.3364485981308412, 0.08411214953271028, 1.0934579439252337,\n",
       "       89.6355140186916, 25.017740421979273, 188.0, 91.0,\n",
       "       18.974025974025974, 11.688311688311689, 5.662337662337662,\n",
       "       7.285714285714286, 0.37662337662337664, 0.2857142857142857,\n",
       "       0.012987012987012988, 1.5194805194805194, 2.6623376623376624,\n",
       "       2.5064935064935066, 0.8831168831168831, 1.9610389610389611,\n",
       "       0.4155844155844156, 0.4025974025974026, 0.1038961038961039,\n",
       "       4.779220779220779, 13.857142857142858, 0.33766233766233766,\n",
       "       0.3116883116883117, 2.1298701298701297, 0.7272727272727273,\n",
       "       0.4025974025974026, 77.50649350649351, 26.400499436906752, 183.0,\n",
       "       85.0, 18.74468085106383, 12.851063829787234, 5.659574468085107,\n",
       "       5.8936170212765955, 0.0851063829787234, 0.06382978723404255, 0.0,\n",
       "       2.425531914893617, 3.2127659574468086, 1.4680851063829787,\n",
       "       0.851063829787234, 2.3191489361702127, 0.574468085106383,\n",
       "       1.0851063829787233, 0.0, 5.787234042553192, 12.148936170212766,\n",
       "       0.8085106382978723, 0.06382978723404255, 2.404255319148936,\n",
       "       1.0212765957446808, 0.14893617021276595, 83.82978723404256,\n",
       "       29.248769288955355, 178.0, 75.0, 17.92436974789916,\n",
       "       10.428571428571429, 3.957983193277311, 7.495798319327731,\n",
       "       0.8151260504201681, 0.3949579831932773, 0.0, 3.2436974789915967,\n",
       "       1.1176470588235294, 2.7394957983193278, 2.2184873949579833,\n",
       "       1.8991596638655461, 1.1680672268907564, 0.5378151260504201,\n",
       "       0.03361344537815126, 7.067226890756302, 10.630252100840336,\n",
       "       0.19327731092436976, 0.6554621848739496, 0.9327731092436975,\n",
       "       0.3697478991596639, 0.680672268907563, 81.15126050420169,\n",
       "       25.044279606337287, 192.0, 94.0, 13.339285714285714,\n",
       "       7.214285714285714, 4.321428571428571, 6.125, 0.5892857142857143,\n",
       "       0.21428571428571427, 0.7678571428571429, 2.3035714285714284,\n",
       "       1.3928571428571428, 1.4464285714285714, 0.42857142857142855,\n",
       "       1.5714285714285714, 0.6964285714285714, 0.6428571428571429,\n",
       "       0.017857142857142856, 4.928571428571429, 8.607142857142858,\n",
       "       0.8392857142857143, 0.625, 4.142857142857143, 0.08928571428571429,\n",
       "       0.35714285714285715, 85.21428571428571, 25.434862747743917, 178.0,\n",
       "       86.0, 11.428571428571429, 8.047619047619047, 3.5714285714285716,\n",
       "       3.380952380952381, 1.0, 1.2380952380952381, 0.0,\n",
       "       2.4285714285714284, 1.1904761904761905, 1.9047619047619047,\n",
       "       0.47619047619047616, 1.7142857142857142, 0.9523809523809523,\n",
       "       0.7142857142857143, 0.047619047619047616, 4.095238095238095,\n",
       "       7.285714285714286, 0.23809523809523808, 0.8571428571428571,\n",
       "       1.0952380952380953, 0.09523809523809523, 0.23809523809523808,\n",
       "       75.9047619047619, 29.765221214737636, 182.0, 83.0,\n",
       "       23.53435114503817, 12.206106870229007, 4.358778625954199,\n",
       "       11.32824427480916, 0.6717557251908397, 0.35877862595419846,\n",
       "       0.648854961832061, 5.938931297709924, 1.4732824427480915,\n",
       "       4.114503816793893, 4.534351145038168, 2.595419847328244,\n",
       "       1.4732824427480915, 1.0076335877862594, 0.6412213740458015,\n",
       "       12.099236641221374, 11.770992366412214, 0.5877862595419847,\n",
       "       0.4198473282442748, 2.5267175572519083, 0.3511450381679389,\n",
       "       0.7022900763358778, 82.87786259541984, 24.745057228787715, 181.0,\n",
       "       77.0, 16.917355371900825, 9.239669421487603, 3.024793388429752,\n",
       "       7.677685950413223, 0.32231404958677684, 0.34710743801652894,\n",
       "       0.049586776859504134, 3.8595041322314048, 1.6942148760330578,\n",
       "       2.8264462809917354, 1.3140495867768596, 1.9834710743801653,\n",
       "       0.7107438016528925, 0.7024793388429752, 0.008264462809917356,\n",
       "       5.661157024793388, 11.40495867768595, 0.14049586776859505,\n",
       "       0.17355371900826447, 1.2231404958677685, 0.9504132231404959,\n",
       "       0.38016528925619836, 78.0495867768595, 26.36142850184954, 186.0,\n",
       "       86.0, 22.846774193548388, 15.040322580645162, 3.879032258064516,\n",
       "       7.806451612903226, 0.5080645161290323, 0.4435483870967742,\n",
       "       0.25806451612903225, 3.217741935483871, 2.5403225806451615,\n",
       "       3.3225806451612905, 3.6370967741935485, 2.903225806451613,\n",
       "       0.9596774193548387, 0.9919354838709677, 0.25806451612903225,\n",
       "       8.209677419354838, 14.274193548387096, 0.20161290322580644,\n",
       "       0.2661290322580645, 1.0161290322580645, 0.33064516129032256,\n",
       "       0.29838709677419356, 82.95967741935483, 29.18542629764097],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X_train[0]))\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''modified: player_stats_2018 -> player_stats to test performance'''\n",
    "X_test = [0]*len(test)\n",
    "for i in range(0,len(test)):\n",
    "    player_list = []\n",
    "    j = 0\n",
    "    for j in range(0,len(player_stats_2018)):\n",
    "        if player_stats_2018[j][0] in test[i][-1]:\n",
    "            player_list.append(player_stats_2018[j][1:])\n",
    "    X_test[i] = player_list\n",
    "    \n",
    "X_test = [np.concatenate(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "scaled_X_train = sc.fit_transform(X_train)\n",
    "scaled_X_test = sc.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = np.hstack((scaled_X_train, opp_teams_train))\n",
    "scaled_X_test = np.hstack((scaled_X_test, opp_teams_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train = np.asarray(scaled_X_train).astype(np.float32)\n",
    "scaled_X_test = np.asarray(scaled_X_test).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.01844740e+00  2.20202398e+00 -1.02666068e+00 -8.59741628e-01\n",
      "  1.59570828e-01 -1.01767027e+00  2.18482089e+00  1.81413805e+00\n",
      "  2.59483910e+00 -7.08010912e-01 -1.32524836e+00 -6.38437629e-01\n",
      " -2.42155850e-01 -8.17581788e-02  1.21390557e+00  1.96432674e+00\n",
      " -1.78979442e-01  4.14096832e-01 -1.64545846e+00  2.78368378e+00\n",
      "  2.37161303e+00  1.13839634e-01 -1.13639760e+00  2.00509056e-02\n",
      " -1.74249142e-01  6.54445171e-01 -1.00790203e+00 -1.22623503e+00\n",
      "  9.64351952e-01  1.40856278e+00 -4.91763204e-01  2.62705922e-01\n",
      " -4.28315289e-02  1.83535621e-01 -3.42217892e-01  7.75135815e-01\n",
      "  3.64111513e-02  1.99175346e+00  1.37013912e+00  5.44578254e-01\n",
      "  3.92572224e-01  3.90220582e-01 -5.09226620e-01  9.67815042e-01\n",
      "  7.51691639e-01 -6.26882374e-01 -2.27324918e-01 -4.57072705e-01\n",
      "  6.72446847e-01  1.52015984e+00 -1.38757844e-02  8.39664698e-01\n",
      " -1.44709766e+00 -3.86754900e-01 -1.60151571e-01  1.11571677e-01\n",
      " -7.12938607e-02 -4.23494756e-01  7.96422064e-01  5.72392702e-01\n",
      " -3.50167215e-01 -5.86584091e-01 -7.51319408e-01  1.00160860e-01\n",
      " -5.03492802e-02  1.70830920e-01 -1.36650527e+00  1.82704758e-02\n",
      " -4.21325237e-01  2.07476169e-01 -3.90404612e-01  4.88340497e-01\n",
      "  8.76508415e-01 -6.18015468e-01 -6.51337385e-01  8.59850645e-01\n",
      " -1.04335070e+00  8.07193637e-01  1.64624441e+00  1.74371719e+00\n",
      " -4.73773688e-01 -5.13739586e-01 -2.06921354e-01 -3.28604907e-01\n",
      " -5.85749567e-01 -5.52466035e-01  4.95582294e+00 -8.30577135e-01\n",
      " -4.38740641e-01 -4.90063548e-01  3.75749677e-01 -4.93231863e-01\n",
      "  2.85152465e-01  5.36445202e-03  4.46220756e-01 -3.03068608e-02\n",
      " -6.31643116e-01  1.03077102e+00 -5.12837708e-01  4.91115361e-01\n",
      " -9.71746206e-01 -2.15991899e-01  6.93407178e-01  5.39157212e-01\n",
      " -1.39607882e+00 -7.66245544e-01 -1.88585579e-01 -3.03447425e-01\n",
      "  7.40044340e-02 -1.83742121e-02 -9.00055051e-01 -1.09652257e+00\n",
      " -3.34511220e-01  2.16389343e-01  3.88708711e-01 -1.14784527e+00\n",
      " -5.19342124e-01 -1.23597836e+00  1.16990045e-01 -5.46583354e-01\n",
      " -6.60217762e-01 -2.98398048e-01 -1.43600643e-01 -4.61172104e-01\n",
      " -9.30829406e-01  1.20447063e+00 -8.75143945e-01 -8.76057506e-01\n",
      "  4.84644890e-01  2.32992101e+00 -4.45938289e-01 -5.50536692e-01\n",
      "  2.06538178e-02  3.61965507e-01 -4.03168239e-02 -3.72803718e-01\n",
      " -3.70214492e-01 -9.56267677e-03 -3.16840559e-01  8.31631899e-01\n",
      "  3.96491541e-03  5.92689633e-01  2.24412307e-01  6.05485499e-01\n",
      " -3.94479573e-01  4.12750632e-01 -6.49369836e-01 -1.49481706e-02\n",
      " -3.40373032e-02 -2.62380779e-01 -3.85866642e-01 -5.85323930e-01\n",
      " -9.26321805e-01  4.88218606e-01  2.94998318e-01  6.75878882e-01\n",
      " -2.23932815e+00 -1.79396856e+00 -8.69424164e-01 -6.85183704e-01\n",
      " -1.00917721e+00 -8.22573543e-01  2.12573576e+00  1.27610278e+00\n",
      " -3.10834497e-01 -1.02118766e+00 -1.32025838e+00 -7.67862722e-02\n",
      " -6.20894313e-01 -9.11527634e-01 -8.13124835e-01 -5.61201215e-01\n",
      " -5.21411479e-01 -3.91945899e-01 -1.10778201e+00 -2.54675835e-01\n",
      "  1.39697802e+00 -9.68735993e-01 -3.73270482e-01  1.83067274e+00\n",
      " -3.80496979e-01  1.27892768e+00  9.65844765e-02  1.52280256e-01\n",
      "  4.34780389e-01  9.31507707e-01  1.80561990e-01 -1.21966630e-01\n",
      " -3.76057118e-01 -1.47538826e-01 -3.17913890e-01 -9.23288643e-01\n",
      "  2.10237384e+00  9.19676661e-01 -5.69255590e-01  1.63021255e-02\n",
      " -9.66885030e-01 -9.91296113e-01 -2.62473077e-01 -4.84205484e-01\n",
      "  7.98125505e-01 -5.31907856e-01 -6.86445892e-01 -7.08886981e-02\n",
      "  2.20003581e+00 -3.99330966e-02 -2.61059054e-03 -5.75318336e-01\n",
      "  8.62952054e-01 -8.77507776e-02 -1.36710978e+00 -1.65476370e+00\n",
      " -1.03079915e+00 -7.96154022e-01 -1.06037199e+00 -1.27924418e+00\n",
      " -2.89515406e-01 -5.92952669e-01  1.48770660e-01 -1.77382731e+00\n",
      " -8.36459458e-01 -1.87479198e+00 -2.88219929e-01 -1.28508878e+00\n",
      " -7.09197640e-01 -1.22119641e+00 -1.05726445e+00 -3.89292985e-01\n",
      " -8.81339192e-01  1.58028209e+00  8.07775617e-01 -1.57264006e+00\n",
      "  1.00902176e+00 -6.94184899e-01 -4.66486692e-01 -3.55990887e-01\n",
      "  1.88912308e+00  1.50829685e+00 -1.96380630e-01  1.77415168e+00\n",
      " -4.93768156e-01 -1.65400565e-01 -2.67329454e-01  1.73066533e+00\n",
      " -1.35765910e-01  1.56286085e+00  2.43274498e+00  3.11885047e+00\n",
      "  1.15081191e+00  3.31890845e+00  2.06382036e+00  2.19202566e+00\n",
      "  1.22303951e+00 -5.74607611e-01 -4.45406020e-01 -6.55642629e-01\n",
      " -8.92122149e-01  3.84558648e-01  2.38947019e-01  1.93386769e+00\n",
      " -1.56315839e+00 -1.00577784e+00 -1.12200952e+00 -1.03267169e+00\n",
      " -1.57249045e+00 -9.32106316e-01  4.66792613e-01  9.46148396e-01\n",
      " -2.81161517e-01  8.31250906e-01 -1.25967360e+00 -3.16626966e-01\n",
      " -4.61651236e-01 -9.53126252e-01 -1.69294283e-01 -4.96337026e-01\n",
      " -6.33032620e-01 -4.44789946e-01 -1.54205847e+00 -6.02771878e-01\n",
      "  1.76988661e-01 -6.44243240e-01 -2.58436650e-01  1.20078540e+00\n",
      " -8.80987048e-01 -6.14234805e-01  7.99440145e-02  4.11849290e-01\n",
      "  2.08394599e+00  1.96126330e+00  9.95383784e-02  1.67958879e+00\n",
      "  1.02314603e+00  1.39440393e+00 -1.50380507e-01  1.02968299e+00\n",
      " -1.41474873e-01  3.18832922e+00  2.64148068e+00  2.40397978e+00\n",
      "  2.98444819e+00  9.83317554e-01  4.28752327e+00  3.23564672e+00\n",
      "  5.81013680e-01  1.35458398e+00  4.58480924e-01 -4.88155395e-01\n",
      "  9.17893589e-01  1.01531291e+00  3.93393368e-01 -2.26932280e-02\n",
      "  3.21810246e-01  1.26075876e+00 -1.01650715e+00 -1.26015413e+00\n",
      "  5.48527598e-01 -5.40503204e-01 -1.01527798e+00 -1.15151000e+00\n",
      " -2.44485617e-01 -1.26474690e+00  1.87651470e-01 -1.71205485e+00\n",
      " -8.97884727e-01 -1.90497994e+00 -1.04316795e+00 -7.95606554e-01\n",
      " -6.80050731e-01 -1.03574765e+00 -6.87638700e-01  3.09613384e-02\n",
      " -8.59150469e-01  1.07060695e+00 -5.46764731e-01 -1.50005662e+00\n",
      "  8.29555511e-01  1.60493612e+00  7.74105906e-01  1.78266656e+00\n",
      " -4.49407935e-01  3.37687403e-01  1.80072951e+00 -1.10235500e+00\n",
      "  3.17117357e+00  3.64480472e+00 -2.67201066e-01 -1.24835014e+00\n",
      " -1.46573687e+00  1.15024877e+00 -9.88799930e-01  1.71147692e+00\n",
      "  3.68944883e-01  1.75364769e+00  1.05427849e+00  5.81192374e-02\n",
      " -6.05295718e-01  2.31968665e+00  3.27311444e+00 -4.91088331e-01\n",
      " -6.40053451e-01  2.91878033e+00  1.12158382e+00  1.24815196e-01\n",
      "  6.32210746e-02  3.79706413e-01  6.23436093e-01  9.80484605e-01\n",
      "  1.23718953e+00  7.99154043e-02 -4.46479708e-01 -4.10685599e-01\n",
      " -2.78718501e-01 -1.25377822e+00  1.23702896e+00  2.59281993e-01\n",
      " -4.53106135e-01 -2.70840496e-01 -1.27194512e+00 -1.37031209e+00\n",
      " -4.21837568e-02 -6.17452383e-01  1.16904831e+00 -3.75946045e-01\n",
      " -4.17027295e-01  1.08911738e-01  6.26132488e-01 -6.97285961e-03\n",
      " -5.54616034e-01  5.19843757e-01 -6.30304575e-01 -4.10749525e-01\n",
      "  5.04213333e-01  1.36587727e+00  1.31788397e+00 -5.27084947e-01\n",
      " -9.49192107e-01 -1.08273327e+00 -3.13341349e-01 -4.49413031e-01\n",
      "  1.81161928e+00 -7.49732137e-01 -5.35453856e-01  4.38997477e-01\n",
      " -8.02813768e-01  9.91699874e-01 -8.01566839e-01 -2.11280301e-01\n",
      "  5.99507153e-01  6.53691113e-01 -8.66607130e-01  1.57338291e-01\n",
      "  1.40161550e+00 -1.04528689e+00  3.39913398e-01  1.22667086e+00\n",
      " -1.26598656e+00 -1.64062715e+00  3.44406575e-01  5.10021269e-01\n",
      " -1.45559072e-01  9.94785428e-02  4.39434737e-01 -4.22593877e-02\n",
      " -3.21243852e-01  3.41486126e-01 -4.48036939e-01  5.40032983e-01\n",
      "  4.81905192e-01 -4.15722996e-01  1.17895401e+00 -1.00090158e+00\n",
      " -5.92681587e-01  4.71105576e-01  1.49807349e-01 -7.00746238e-01\n",
      "  2.40282044e-01 -7.76634276e-01 -4.47780304e-02  1.19439054e+00\n",
      " -1.48971051e-01 -2.16849018e-02  5.67605197e-01  6.59223378e-01\n",
      " -7.42998838e-01 -8.37630332e-01  1.89746946e-01 -4.96129662e-01\n",
      "  1.46582359e-02 -6.34762228e-01 -1.87547579e-01 -5.70535362e-01\n",
      " -1.93428919e-01 -9.03183162e-01 -8.67747426e-01 -1.19223964e+00\n",
      " -4.25289214e-01 -6.47794366e-01 -7.53185272e-01 -7.11591482e-01\n",
      " -5.42640507e-01  6.87443733e-01  2.12459594e-01  1.32297969e+00\n",
      " -6.51811004e-01 -2.13415131e-01  4.82295781e-01  1.34982303e-01\n",
      " -1.24868858e+00 -2.59940833e-01 -1.20215583e+00 -6.45272195e-01\n",
      " -4.81563568e-01 -1.42725074e+00  7.01374948e-01  2.28720951e+00\n",
      " -3.00687462e-01 -5.21926820e-01 -4.37115788e-01 -5.35955250e-01\n",
      " -8.87122750e-01 -9.57907379e-01  4.70631093e-01 -4.27976847e-01\n",
      " -5.60187399e-01 -1.09609580e+00 -1.00078762e+00 -5.24410009e-01\n",
      "  5.23687184e-01 -6.56251431e-01 -7.01818109e-01 -7.68225193e-01\n",
      " -7.97872007e-01  1.27177310e+00 -7.12775111e-01 -6.30357146e-01\n",
      "  1.35588694e+00  8.22264075e-01  2.49512240e-01  1.42590904e+00\n",
      "  3.06616038e-01 -7.71800578e-02 -1.45580888e-01  2.48487782e+00\n",
      " -2.78784901e-01  1.74967718e+00  1.89915383e+00  7.40503907e-01\n",
      "  2.29734182e+00  6.02466702e-01  3.05233932e+00  2.59022403e+00\n",
      "  3.74575406e-01  3.29335123e-01 -8.89662504e-02  1.92658499e-01\n",
      " -1.19826525e-01  1.34668362e+00  2.06053272e-01 -1.10446326e-01\n",
      " -9.39118743e-01 -1.48130322e+00  4.14729863e-02 -1.26245141e-01\n",
      " -9.55719054e-01  2.35305682e-01 -3.54077727e-01  2.93934420e-02\n",
      " -2.60237128e-01  7.68511176e-01 -4.40132767e-02  5.54696143e-01\n",
      " -2.37602577e-01 -3.21181655e-01 -1.87619641e-01 -3.45093429e-01\n",
      " -7.50246465e-01 -2.40613699e-01  2.81243414e-01 -7.45891929e-01\n",
      " -5.82208276e-01 -5.72489500e-01  8.96540403e-01  1.12995885e-01\n",
      " -4.11876291e-01  3.85451853e-01 -3.43319803e-01 -1.78448915e-01\n",
      "  1.32839513e+00  2.08844447e+00 -2.82697678e-01  1.96842268e-01\n",
      " -1.96416825e-01  2.42513102e-02 -1.81150272e-01  2.97826648e-01\n",
      "  1.04832447e+00  1.02923095e+00  1.64579463e+00  1.67202759e+00\n",
      "  6.49656713e-01  7.60679007e-01  1.02242529e+00  1.20919585e+00\n",
      "  1.06081343e+00 -6.03963852e-01 -4.46841657e-01 -6.41826093e-01\n",
      " -2.64618039e-01 -5.42389572e-01  1.94161251e-01  1.44653380e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  1.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n"
     ]
    }
   ],
   "source": [
    "print(scaled_X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the ANN\n",
    "ann = tf.keras.models.Sequential()\n",
    "# First layer\n",
    "ann.add(tf.keras.layers.Dense(units = 4, activation = 'relu'))\n",
    "# Second layer\n",
    "ann.add(tf.keras.layers.Dense(units = 4, activation = 'relu'))\n",
    "# Output layer\n",
    "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 590us/step - loss: 0.6897 - accuracy: 0.5223\n",
      "78/78 [==============================] - 0s 413us/step - loss: 0.6774 - accuracy: 0.5985\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6805 - accuracy: 0.6250WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "13/13 [==============================] - 0s 615us/step - loss: 0.6819 - accuracy: 0.5588\n",
      "78/78 [==============================] - 0s 590us/step - loss: 0.6718 - accuracy: 0.5921\n",
      "78/78 [==============================] - 0s 397us/step - loss: 0.6545 - accuracy: 0.6281\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.6648 - accuracy: 0.6103\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.6604 - accuracy: 0.6562WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 628us/step - loss: 0.6468 - accuracy: 0.6391\n",
      "78/78 [==============================] - 0s 397us/step - loss: 0.6245 - accuracy: 0.6642\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.6489 - accuracy: 0.6275\n",
      "78/78 [==============================] - 0s 782us/step - loss: 0.6225 - accuracy: 0.6541\n",
      "78/78 [==============================] - 0s 462us/step - loss: 0.6003 - accuracy: 0.6752\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.6402 - accuracy: 0.6275\n",
      "78/78 [==============================] - 0s 603us/step - loss: 0.6026 - accuracy: 0.6699\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.5826 - accuracy: 0.6942\n",
      "13/13 [==============================] - 0s 461us/step - loss: 0.6362 - accuracy: 0.6250\n",
      "78/78 [==============================] - 0s 577us/step - loss: 0.5886 - accuracy: 0.6849\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.5685 - accuracy: 0.7056\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.6425 - accuracy: 0.6324\n",
      "78/78 [==============================] - 0s 603us/step - loss: 0.5750 - accuracy: 0.7019\n",
      "78/78 [==============================] - 0s 397us/step - loss: 0.5543 - accuracy: 0.7153\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.6457 - accuracy: 0.6275\n",
      "78/78 [==============================] - 0s 603us/step - loss: 0.5604 - accuracy: 0.7117\n",
      "78/78 [==============================] - 0s 410us/step - loss: 0.5411 - accuracy: 0.7340\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.6567 - accuracy: 0.6275\n",
      "78/78 [==============================] - 0s 577us/step - loss: 0.5497 - accuracy: 0.7170\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.6677 - accuracy: 0.6562WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 423us/step - loss: 0.5281 - accuracy: 0.7441\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.6705 - accuracy: 0.5938WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "13/13 [==============================] - 0s 615us/step - loss: 0.6572 - accuracy: 0.6397\n",
      "78/78 [==============================] - 0s 667us/step - loss: 0.5382 - accuracy: 0.7328\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.6549 - accuracy: 0.6562WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 462us/step - loss: 0.5171 - accuracy: 0.7486\n",
      "13/13 [==============================] - 0s 461us/step - loss: 0.6653 - accuracy: 0.6348\n",
      "78/78 [==============================] - 0s 693us/step - loss: 0.5294 - accuracy: 0.7303\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.5076 - accuracy: 0.7506\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.6691 - accuracy: 0.6348\n",
      "78/78 [==============================] - 0s 590us/step - loss: 0.5168 - accuracy: 0.7441\n",
      "78/78 [==============================] - 0s 398us/step - loss: 0.4951 - accuracy: 0.7583\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.6845 - accuracy: 0.6225\n",
      "78/78 [==============================] - 0s 564us/step - loss: 0.5061 - accuracy: 0.7449\n",
      "78/78 [==============================] - 0s 410us/step - loss: 0.4843 - accuracy: 0.7652\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.6886 - accuracy: 0.6275\n",
      "78/78 [==============================] - 0s 564us/step - loss: 0.4952 - accuracy: 0.7551\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.4753 - accuracy: 0.7725\n",
      "13/13 [==============================] - 0s 461us/step - loss: 0.6982 - accuracy: 0.6225\n",
      "78/78 [==============================] - 0s 590us/step - loss: 0.4855 - accuracy: 0.7612\n",
      "78/78 [==============================] - 0s 423us/step - loss: 0.4630 - accuracy: 0.7826\n",
      "13/13 [==============================] - 0s 460us/step - loss: 0.7050 - accuracy: 0.6103\n",
      "78/78 [==============================] - 0s 668us/step - loss: 0.4793 - accuracy: 0.7697\n",
      "78/78 [==============================] - 0s 462us/step - loss: 0.4549 - accuracy: 0.7847\n",
      "13/13 [==============================] - 0s 691us/step - loss: 0.7261 - accuracy: 0.6103\n",
      "78/78 [==============================] - 0s 617us/step - loss: 0.4695 - accuracy: 0.7753\n",
      "78/78 [==============================] - 0s 423us/step - loss: 0.4453 - accuracy: 0.7956\n",
      "13/13 [==============================] - 0s 461us/step - loss: 0.7335 - accuracy: 0.6054\n",
      "78/78 [==============================] - 0s 667us/step - loss: 0.4616 - accuracy: 0.7810\n",
      "78/78 [==============================] - 0s 423us/step - loss: 0.4351 - accuracy: 0.8029\n",
      "13/13 [==============================] - 0s 539us/step - loss: 0.7398 - accuracy: 0.6103\n",
      "78/78 [==============================] - 0s 590us/step - loss: 0.4516 - accuracy: 0.7822\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.4275 - accuracy: 0.8054\n",
      "13/13 [==============================] - 0s 461us/step - loss: 0.7427 - accuracy: 0.6005\n",
      "78/78 [==============================] - 0s 564us/step - loss: 0.4412 - accuracy: 0.7851\n",
      "78/78 [==============================] - 0s 410us/step - loss: 0.4178 - accuracy: 0.8114\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.7715 - accuracy: 0.5956\n",
      "78/78 [==============================] - 0s 590us/step - loss: 0.4340 - accuracy: 0.8009\n",
      "78/78 [==============================] - 0s 410us/step - loss: 0.4090 - accuracy: 0.8159\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.7677 - accuracy: 0.6029\n",
      "78/78 [==============================] - 0s 615us/step - loss: 0.4233 - accuracy: 0.8058\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.5215 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 513us/step - loss: 0.4019 - accuracy: 0.8260\n",
      " 1/13 [=>............................] - ETA: 0s - loss: 0.8501 - accuracy: 0.5625WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "13/13 [==============================] - 0s 616us/step - loss: 0.7922 - accuracy: 0.5980\n",
      "78/78 [==============================] - 0s 628us/step - loss: 0.4249 - accuracy: 0.8001\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.3989 - accuracy: 0.8252\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.8006 - accuracy: 0.6152\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.3984 - accuracy: 0.7812WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78/78 [==============================] - 0s 718us/step - loss: 0.4137 - accuracy: 0.8082\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.4872 - accuracy: 0.7500WARNING:tensorflow:Callbacks method `on_test_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 538us/step - loss: 0.3865 - accuracy: 0.8256\n",
      "13/13 [==============================] - 0s 615us/step - loss: 0.8160 - accuracy: 0.6152\n",
      "78/78 [==============================] - 0s 577us/step - loss: 0.4045 - accuracy: 0.8139\n",
      "78/78 [==============================] - 0s 449us/step - loss: 0.3767 - accuracy: 0.8390\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.8420 - accuracy: 0.6225\n",
      "78/78 [==============================] - 0s 615us/step - loss: 0.3936 - accuracy: 0.8208\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.4467 - accuracy: 0.7812WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 462us/step - loss: 0.3692 - accuracy: 0.8390\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.8458 - accuracy: 0.6127\n",
      "78/78 [==============================] - 0s 577us/step - loss: 0.3877 - accuracy: 0.8232\n",
      "78/78 [==============================] - 0s 410us/step - loss: 0.3657 - accuracy: 0.8443\n",
      "13/13 [==============================] - 0s 692us/step - loss: 0.8601 - accuracy: 0.6103\n",
      "78/78 [==============================] - 0s 731us/step - loss: 0.3839 - accuracy: 0.8305\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.3582 - accuracy: 0.8455\n",
      "13/13 [==============================] - 0s 538us/step - loss: 0.8774 - accuracy: 0.6152\n",
      "78/78 [==============================] - 0s 679us/step - loss: 0.3746 - accuracy: 0.8370\n",
      "78/78 [==============================] - 0s 410us/step - loss: 0.3522 - accuracy: 0.8471\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.8979 - accuracy: 0.6176\n",
      "78/78 [==============================] - 0s 577us/step - loss: 0.3758 - accuracy: 0.8305\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.3472 - accuracy: 0.8528\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.8829 - accuracy: 0.6103\n",
      "78/78 [==============================] - 0s 551us/step - loss: 0.3634 - accuracy: 0.8386\n",
      "78/78 [==============================] - 0s 375us/step - loss: 0.3379 - accuracy: 0.8581\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.9369 - accuracy: 0.6029\n",
      "78/78 [==============================] - 0s 577us/step - loss: 0.3821 - accuracy: 0.8240\n",
      "78/78 [==============================] - 0s 388us/step - loss: 0.3417 - accuracy: 0.8544\n",
      "13/13 [==============================] - 0s 692us/step - loss: 0.9300 - accuracy: 0.5980\n",
      "78/78 [==============================] - 0s 590us/step - loss: 0.3586 - accuracy: 0.8370\n",
      "78/78 [==============================] - 0s 462us/step - loss: 0.3319 - accuracy: 0.8662\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.9450 - accuracy: 0.5980\n",
      "78/78 [==============================] - 0s 769us/step - loss: 0.3476 - accuracy: 0.8483\n",
      "78/78 [==============================] - 0s 539us/step - loss: 0.3233 - accuracy: 0.8686\n",
      "13/13 [==============================] - 0s 462us/step - loss: 0.9737 - accuracy: 0.6005\n",
      "78/78 [==============================] - 0s 590us/step - loss: 0.3387 - accuracy: 0.8548\n",
      "78/78 [==============================] - 0s 372us/step - loss: 0.3179 - accuracy: 0.8723\n",
      "13/13 [==============================] - 0s 461us/step - loss: 1.0005 - accuracy: 0.6078\n",
      "78/78 [==============================] - 0s 564us/step - loss: 0.3298 - accuracy: 0.8577\n",
      "78/78 [==============================] - 0s 410us/step - loss: 0.3117 - accuracy: 0.8735\n",
      "13/13 [==============================] - 0s 461us/step - loss: 1.0384 - accuracy: 0.6005\n",
      "78/78 [==============================] - 0s 538us/step - loss: 0.3292 - accuracy: 0.8609\n",
      "78/78 [==============================] - 0s 397us/step - loss: 0.3064 - accuracy: 0.8800\n",
      "13/13 [==============================] - 0s 461us/step - loss: 1.0582 - accuracy: 0.6054\n",
      "78/78 [==============================] - 0s 628us/step - loss: 0.3289 - accuracy: 0.8597\n",
      "78/78 [==============================] - 0s 384us/step - loss: 0.3056 - accuracy: 0.8792\n",
      "13/13 [==============================] - 0s 462us/step - loss: 1.1031 - accuracy: 0.5980\n",
      "78/78 [==============================] - 0s 628us/step - loss: 0.3225 - accuracy: 0.8633\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.2966 - accuracy: 0.8828\n",
      "13/13 [==============================] - 0s 461us/step - loss: 1.0989 - accuracy: 0.6152\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.4462 - accuracy: 0.8125WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 744us/step - loss: 0.3124 - accuracy: 0.8727\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.2936 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 436us/step - loss: 0.2924 - accuracy: 0.8832\n",
      "13/13 [==============================] - 0s 538us/step - loss: 1.1276 - accuracy: 0.6078\n",
      "78/78 [==============================] - 0s 628us/step - loss: 0.3058 - accuracy: 0.8755\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.2787 - accuracy: 0.8750WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 449us/step - loss: 0.2875 - accuracy: 0.8877\n",
      "13/13 [==============================] - 0s 538us/step - loss: 1.1416 - accuracy: 0.6054\n",
      " 1/78 [..............................] - ETA: 0s - loss: 0.3330 - accuracy: 0.8438WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0010s). Check your callbacks.\n",
      "78/78 [==============================] - 0s 590us/step - loss: 0.3062 - accuracy: 0.8739\n",
      "78/78 [==============================] - 0s 397us/step - loss: 0.2824 - accuracy: 0.8901\n",
      "13/13 [==============================] - 0s 461us/step - loss: 1.1750 - accuracy: 0.6029\n",
      "78/78 [==============================] - 0s 577us/step - loss: 0.2956 - accuracy: 0.8852\n",
      "78/78 [==============================] - 0s 410us/step - loss: 0.2774 - accuracy: 0.8921\n",
      "13/13 [==============================] - 0s 463us/step - loss: 1.1947 - accuracy: 0.6152\n",
      "78/78 [==============================] - 0s 564us/step - loss: 0.2929 - accuracy: 0.8832\n",
      "78/78 [==============================] - 0s 410us/step - loss: 0.2707 - accuracy: 0.8962\n",
      "13/13 [==============================] - 0s 538us/step - loss: 1.2131 - accuracy: 0.6103\n",
      "78/78 [==============================] - 0s 590us/step - loss: 0.2900 - accuracy: 0.8816\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.2709 - accuracy: 0.8925\n",
      "13/13 [==============================] - 0s 462us/step - loss: 1.2815 - accuracy: 0.6103\n",
      "78/78 [==============================] - 0s 615us/step - loss: 0.2866 - accuracy: 0.8828\n",
      "78/78 [==============================] - 0s 436us/step - loss: 0.2646 - accuracy: 0.8974\n",
      "13/13 [==============================] - 0s 462us/step - loss: 1.2617 - accuracy: 0.6103\n",
      "78/78 [==============================] - 0s 628us/step - loss: 0.2785 - accuracy: 0.8893\n",
      "78/78 [==============================] - 0s 385us/step - loss: 0.2690 - accuracy: 0.8994\n",
      "13/13 [==============================] - 0s 462us/step - loss: 1.2849 - accuracy: 0.6152\n",
      "78/78 [==============================] - 0s 574us/step - loss: 0.3363 - accuracy: 0.8491\n",
      "78/78 [==============================] - 0s 436us/step - loss: 0.2830 - accuracy: 0.8812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 385us/step - loss: 1.3079 - accuracy: 0.6225\n",
      "78/78 [==============================] - 0s 593us/step - loss: 0.2967 - accuracy: 0.8719\n",
      "78/78 [==============================] - 0s 397us/step - loss: 0.2644 - accuracy: 0.8966\n",
      "13/13 [==============================] - 0s 462us/step - loss: 1.3350 - accuracy: 0.6127\n",
      "78/78 [==============================] - 0s 603us/step - loss: 0.2910 - accuracy: 0.8767\n",
      "78/78 [==============================] - 0s 397us/step - loss: 0.2615 - accuracy: 0.8990\n",
      "13/13 [==============================] - 0s 539us/step - loss: 1.3180 - accuracy: 0.6078\n"
     ]
    }
   ],
   "source": [
    "steps = []\n",
    "accs = []\n",
    "test_accs = []\n",
    "\n",
    "for i in range(0, 50):\n",
    "    ann.fit(scaled_X_train, y_train, epochs = 1)\n",
    "    [loss, accuracy] = ann.evaluate(scaled_X_train, y_train)\n",
    "    [loss_t, accuracy_t] = ann.evaluate(scaled_X_test, y_test)\n",
    "    accs.append(accuracy), steps.append(i), test_accs.append(accuracy_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2496422ea88>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(steps, accs)\n",
    "plt.plot(steps, test_accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-e253700bb8eb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred1' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
